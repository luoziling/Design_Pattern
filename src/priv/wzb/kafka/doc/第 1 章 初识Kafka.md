# 第 1 章 初识Kafka

> 每一次科学家们发生分歧，都是因为掌握的数据不够充分。所以我们可以先就获 取哪一类数据达成一致。只要获取了数据，问题也就迎刃而解了。要么我是对 的，要么你是对的，要么我们都是错的。然后我们继续研究。
>
> 数据——信息——知识——智慧

## 1.1　发布与订阅消息系统

> 在正式讨论 Apache Kafka（以下简称 Kafka）之前，先来了解发布与订阅消息系统的概念， 并认识这个系统的重要性。数据（消息）的发送者（发布者）不会直接把消息发送给接收 者，这是发布与订阅消息系统的一个特点。发布者以某种方式对消息进行分类，接收者 （订阅者）订阅它们，以便接收特定类型的消息。发布与订阅系统一般会有一个 broker，也 就是发布消息的中心点。

- 发送者不会直接把消息发送给接收者
- 发送者消息分类，接收者订阅特定消息
- 消息队列的作用
  - 进程间通信
  - 解耦

### 1.1.1　如何开始

- 发布于订阅消息的场景

  - 简单的消息队列
  - 进程间通道

- 消息发送者和消费者直接连接，强耦合，随着场景的复杂化导致技术负债，一个改动需要改动大量地方

  ![image-20210914173927270](第 1 章 初识Kafka.assets/image-20210914173927270.png)

- 可通过中间层解耦来降低复杂度，同一管理消息的发布与订阅

  ![image-20210914174002229](第 1 章 初识Kafka.assets/image-20210914174002229.png)

- 

### 1.1.2　独立的队列系统

- 不同场景都构建自己的发布订阅系统

  ![image-20210914174104223](第 1 章 初识Kafka.assets/image-20210914174104223.png)

- 缺陷

  - 大量重复代码
  - 扩展不方便
  - 不便于管理

- 聚合多个单一订阅发布系统，统一集中管理

## 1.2 Kafka登场

> Kafka 就是为了解决上述问题而设计的一款基于发布与订阅的消息系统。它一般被称为 “分布式提交日志”或者“分布式流平台”。文件系统或数据库提交日志用来提供所有事务 的持久记录，通过重放这些日志可以重建系统的状态。同样地，Kafka 的数据是按照一定 顺序持久化保存的，可以按需读取。此外，Kafka 的数据分布在整个系统里，具备数据故 障保护和性能伸缩能力。

- 基于发布 订阅的消息系统，解决进程通信/消息队列
- 持久化、分布式
- 故障保护/性能伸缩

### 1.2.1　消息和批次

- kafka中数据单元叫**消息**
- 一条消息类似数据库一行记录
- 字节数组组成消息 消息没有格式/含义
- <key,message> key用作数据分析 一致性hash算法
- 批次=》一组消息，可以组为单位写入主题和分区
  - 提升吞吐量
  - 提高网络延迟 大量消息传输

### 1.2.2　模式

- 解决消息的难以阅读
- 模式定义消息内容的类型，消息元数据
- Apache Avro
- 模式+序列化

### 1.2.3　主题和分区

- Kafka 的消息通过**主题**进行分类。
  - 主题=表/文件夹
- 一个主题多个**分区**
  - 分区=提交日志
  - 主题整体消息顺序乱序，但分区内消息有序
  - 分区可分布在不同服务器提供分布式+消息冗余能力
- **流**数据处理机制
  - Kafka Streams、Apache Samza 和 Storm 这些框 架以实时的方式处理消息，也就是所谓的流式处理。
- 

### 1.2.4　生产者和消费者

- kafka客户端被分为生产者/消费者
- 高级客户端API
  - 数据集成 Kafka Connect API
  - 流式处理 Kafka Streams
- 生产者
  - 创建消息，消息被发布到指定主题，根据分区器写到固定分区
  - 消息key 一致性hash算法映射到指定分区
- 消费者
  - 读取消息，订阅/读者
  - 订阅一个/多个 主题 按序读取数据
  - 偏移量表示消息读取进度，偏移量存储在zk/kafka
  - 偏移量防止重启后的数据丢失
  - 消费者与分区
    - 消费者是消费者组的一部分
    - 一个分区同时只能被一个消费者组的一个消费者读取
  - ![image-20210915105807076](第 1 章 初识Kafka.assets/image-20210915105807076.png)
  - 消费 者与分区之间的映射通常被称为消费者对分区的**所有权关系**。
- 

### 1.2.5 broker和集群

> 一个独立的 Kafka 服务器被称为 broker。

- broker接收消息，设置偏移量，保存到磁盘
- 为消费者提供服务，响应分区读取返回磁盘上的消息
- 单个broker轻松处理数千个分区及百万计消息量
- broker 是**集群**的组成部分。每个集群都有一个 broker 同时充当了**集群控制器**的角色（自动 从集群的活跃成员中选举出来）。
- broker中存储主题多个分区，分区分为leader/follower
- kafka默认保留起添内的消息，要么保留一定大小的字节数
- 超出上限删除过期消息
- TOPIC可配置自定义消息数，可将消息保留到不再使用
- ![image-20210915112100280](第 1 章 初识Kafka.assets/image-20210915112100280.png)

### 1.2.6　多集群

随着 Kafka 部署数量的增加，基于以下几点原因，最好使用多个集群。

- 数据类型分离
- 安全需求隔离
- 多数据中心（灾难恢复）

集群需要消息复制

- 单集群消息复制
- MirrorMaker实现集群间消息复制

## 1.3　为什么选择Kafka

### 1.3.1 多个生产者

- 多生产者意味着多数据源，每个生产者可以向不同topic

### 1.3.2　多个消费者

- 用消费者组来确保同一组内的消息只被消费一次
- 多个消费者支持消息的重复消费

### 1.3.3　基于磁盘的数据存储

- 数据保留特性支持消息的非实时消费
- 持久化+集群确保数据安全性，通过保留上一次消费的进度确保消息消费的安全

### 1.3.4　伸缩性

- 集群容错，动态扩展

### 1.3.5　高性能

- 高性能订阅消息系统，横向扩展生产者、消费者、broker

## 1.4　数据生态系统

kafka为数据生态系统带来了循环系统，解耦生产者和消费者，生产者不用关心谁处理数据，消费者不用关心数据来源

![image-20210915140700993](第 1 章 初识Kafka.assets/image-20210915140700993.png)

### 使用场景

- 活动跟踪
  - 用户操作记录追踪计入MQ 用于数据分析 
- 传递消息
  - 定义消息基础
  - 正常流程和消息装饰和具体发送进行解耦
  - 不需要在多个应用程序上开发重复的功能，而且可以在公共组 件上做一些有趣的转换，比如把多个消息聚合成一个单独的通知，而这些工作是无法在其 他地方完成的。
- 度量指标和日志记录
  - 收集应用程序的度量指标/日志，监控/日志分析
  - 日志中间节转发
- 提交日志
  - 数据库数据同步，数据恢复
- 流处理

## 1.5　起源故事

> Kafka 是为了解决 LinkedIn 数据管道问题应运而生的。它的设计目的是提供一个高性能的 消息系统，可以处理多种数据类型，并能够实时提供纯净且结构化的用户活动数据和系统 度量指标。
>
> 数据为我们所做的每一件事提供了动力。
>
> ——Jeff Weiner，LinkedIn CEO

### 1.5.1 LinkedIn的问题

- LinkedIn 有一个数据收集系统和应用程序指标，它使用自定义的收集器 和一些开源工具来保存和展示内部数据。
- 系统监控/用户追踪服务不同，监控泰国本中，数据格式不同
  - 多个接收者，不同的数据类型/格式
- 需要一个系统实时访问数据，通过横向扩展访问大量数据，基于ActiveMQ

### 1.5.2 Kafka的诞生

LinkedIn 的开发团队由 Jay Kreps 领导。Jay Kreps 是 LinkedIn 的首席工程师，之前负责分 布式键值存储系统 Voldemort 的开发。初建团队成员还包括 Neha Narkhede，不久之后， Jun Rao 也加入了进来。他们一起着手创建一个消息系统，可以同时满足上述的两种需求， 并且可以在未来进行横向扩展。他们的主要目标如下：

- 推送/拉取 解耦生产者/消费者
- 为消息传递系统中的消息提供数据持久化，支持多个消费者
- 系统优化实现高吞吐量
- 随着数据流增长进行横向扩展
- pub/sub 客户端主动拉取 持久化 高性能 动态扩展

### 1.5.3　走向开源

- 2010在github开源
- 大数据管道

### 1.5.4　命名

## 1.6 小结

- MQ 的基本概念
  - 主要用于解耦/进程间通信
    - 进程间消息通信的方案
      - 管道
      - MQ
      - 共享内存
      - socket
  - 系统间数据交互的直接连接到MQ的解耦+灵活
- kafka基础概念
  - 消息，具体的数据描述类似数据库一行记录，可以分批操作
  - 模式，消息是字节码数组无意义通过模式对消息做额外补充说明
  - 主题和分区，不同的消息存储在不同主题中，类似数据库的表，分区与数据库概念的分表类似
  - 生产者和消费者，kafka作为中间件允许毒功而生产者/消费者，生产者向特定topic推送数据，消费者从订阅的topic中主动拉取想要的数据
  - broke=》kafka实例 高可用基础
- 优势
  - 多个生产者/消费者
  - 基于磁盘持久化
  - 伸缩性 动态扩展
  - 高性能
- 使用场景
  - 用户跟踪
  - 发送消息
  - 系统基础日志收集
  - 数据库日志传递
  - 流处理
- 
